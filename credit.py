# -*- coding: utf-8 -*-
"""Credit

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Agt-s6BXKJUNAPBFVc05naDgnOXxV93y
"""

# importer les packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt # pour la visualisation
import seaborn as sns # aussi pour la visualisation
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import pickle # pour generer mon model

#lire la bd
df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Machine Learning/Credit App/dataset/train_u6lujuX_CVtuZ9i.csv')
df

# on constate que notre bd a 614 lignes et 13 colones mais seulement une dixaine de ligne s'affiche
# alors pour afficher toutes les lignes:

pd.set_option('display.max_row',df.shape[0]+1)
df

# afficher uniquement 10 lignes de notre bd
pd.set_option('display.max_row',10)
df

# on verifie s'il y a des valeures manquantes; elles sont representées par NAN 
# pour les voir:
df.info()

# afficher le nombre de valeures manquantes par colone
df.isnull().sum().sort_values(ascending=False)

# on peut aussi voire si on a des valeures anormales
df.describe()

# renseigner les valeures manquantes: pour les valeure string, la politique est qu'on remplace cette valeure manquante par celle qui se repete le plus dans cette colone
# pour les valeures numeriques on les renseignent par la valeure qui est a coté

# 1- on divise notre bd en 2 : liste des variables categoriques(nos string) et une liste des variables numeriques
cat_data=[]
num_data=[]
for i,c in enumerate(df.dtypes):
   if c==object:
     cat_data.append(df.iloc[:,i]) # iloc permet de selectionner une colone et i cest le nom de notre colone
   else:
    num_data.append(df.iloc[:,i])
cat_data=pd.DataFrame(cat_data).transpose() #ici c'est la transformation de la liste en une bd
num_data=pd.DataFrame(num_data).transpose()
cat_data # affiche la bd de la partie categoriques
#num_data

# 2- pour les variables categoriques on va remplacer les valeures manquantes par celles que se repetent le plus
cat_data=cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))
cat_data.isnull().sum().any() # verifi s'il y a encore une valeure manquante

# 3- Pour les variables numerique on remplace la valeure manquante par la valeur precedante de la meme colone
num_data.fillna(method='bfill', inplace=True)
num_data.isnull().sum().any() # verifi s'il y a encore une valeure manquante

# Transformer la colonne target en 1 pour Yes et 0 pour No
target_value={'Y':1,'N':0}
target=cat_data['Loan_Status'] # creer la colone target
cat_data.drop('Loan_Status',axis=1,inplace=True)# supprimer l'ancienne colone loan_Status
target=target.map(target_value)
target

# remplacer le reste des variables categoriques par des valeurs num 0 , 1, 2...
# Nous pourions aussi le faire manuellement comme celle da la colone target si haut
# Mais nous avons prefere utiliser la fonction le.fit_transform
le=LabelEncoder()
for i in cat_data:
  cat_data[i]=le.fit_transform(cat_data[i])
cat_data

#supprimer loan_id(ous l'avons juge iutile pour nous)
cat_data.drop('Loan_ID',axis=1,inplace=True)

#concatener cat_Data et num_data et specifier la colonne target
X=pd.concat([cat_data,num_data],axis=1)
y=target

X

y

# Analyse Exploratoire 
# commencons par la vatiable target
# combien de credits sont acceptes et combien rejete?
target.value_counts()

#la bd utilisée pour EDA
df=pd.concat([cat_data,num_data, target],axis=1)

plt.figure(figsize=(8,6))
sns.countplot(target)
yes=target.value_counts()[0]/len(target)
no=target.value_counts()[1]/len(target)
print(f'le pourcentage des credits accordés est:{yes}' )
print(f'le pourcentage des credits non accordés est:{no}' )

# credit history
grid=sns.FacetGrid(df, col='Loan_Status', size=3.2,aspect=1.6)
grid.map(sns.countplot,'Credit_History')

# Sexe
grid=sns.FacetGrid(df, col='Loan_Status', size=3.2,aspect=1.6)
grid.map(sns.countplot,'Gender')

# Marier ou pas
grid=sns.FacetGrid(df, col='Loan_Status', size=3.2,aspect=1.6)
grid.map(sns.countplot,'Married')

# Education
grid=sns.FacetGrid(df, col='Loan_Status', size=3.2,aspect=1.6)
grid.map(sns.countplot,'Education')

#revenu du demandeur
plt.scatter(df['ApplicantIncome'], df['Loan_Status'])

plt.scatter(df['CoapplicantIncome'], df['Loan_Status'])

df.groupby('Loan_Status').median()

# realisation du Model
# nous allons diviser notre BD en une bd d'emtrainement et une bd de test
sss=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)
for train,test in sss.split(X,y):
  X_train,X_test=X.iloc[train],X.iloc[test]
  y_train,y_test=y.iloc[train],y.iloc[test]

print('X_train taille:',X_train.shape)
print('X_test taille:',X_test.shape)
print('y_train taille:',y_train.shape)
print('y_test taille:',y_test.shape)

# creer notre model
# On va appliquer trois algorithmes: Logistic Regression, KNN, DecisionTree

models={
    'LogisticRegression':LogisticRegression(random_state=42),
    'KNeighborsClassifier':KNeighborsClassifier(),
    'DecisionTreeClassifier':DecisionTreeClassifier(max_depth=1,random_state=42)
}

# La fonction precision(accuracy)
def accu(y_true,y_pred,retu=False):
  acc=accuracy_score(y_true,y_pred)
  if retu:
    return acc
  else:
      print(f'La precision du model est:{acc}')
      
# la fonction d'application des models
def train_test_eval(models,X_train,y_train,X_test,y_test):
  for name,model in models.items():
    print(name,':')
    model.fit(X_train,y_train)
    accu(y_test,model.predict(X_test))
    print('-'*30)

train_test_eval(models,X_train,y_train,X_test,y_test)

# On cree une nouvelle bd pour faire applquer notre model qui sera implemente sur l'interface de l'App, on choisira les variables qui on un impact...
X_2=X[['Credit_History','Married','CoapplicantIncome']]

# Il faut definir de nouvel train et test

sss=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)
for train,test in sss.split(X_2,y):
  X_train,X_test=X_2.iloc[train],X_2.iloc[test]
  y_train,y_test=y.iloc[train],y.iloc[test]

print('X_train taille:',X_train.shape)
print('X_test taille:',X_test.shape)
print('y_train taille:',y_train.shape)
print('y_test taille:',y_test.shape)

train_test_eval(models,X_train,y_train,X_test,y_test)

# Le meilleur model c'est LogisticRegression. Nous allons l'appliquer seul maintenant
# appliquer la regression logistique sur notre bd

Classifier=LogisticRegression()
Classifier.fit(X_2,y)

# Enregistrer le model
pickle.dump(Classifier,open('model.pkl','wb'))

"""Apres avoir enregistrer notre model, nous allons utiliser ***Flask*** pour creer la page html de notre App, pour cela nous installerons PyCharm sur notre pc pour l'implementer.
Pour Flask, nous utiliserons le template Deployment_flask_master.zip se trouvant dans MyDrive, a l'interieur de ce fichier nous allons copier les dossiers suivants: **static et templates**, en suite le fichier **app.py**
Pour terminer nous modifierons **app.py et index.html** selon notre convenance.
"""